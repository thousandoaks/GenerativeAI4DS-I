{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNAGw/LIhsiZNqQKV/uqPN6"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# GenerativeAI4DS-I\n",
        "## Lab. Financial Assistant\n",
        "\n",
        "\n",
        "##  What I hope you'll get out of this lab\n",
        "* The feeling that you'll \"know where to start\" when you have to consume OpenAI services.\n",
        "* Follow OpenAI's best practices on how to develop assistants"
      ],
      "metadata": {
        "id": "rigxDZTATdb8"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WBJEYnwHTb11",
        "outputId": "973bce87-e4d6-44a5-b0f0-6e6f48221360"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: openai in /usr/local/lib/python3.12/dist-packages (2.15.0)\n",
            "Requirement already satisfied: anyio<5,>=3.5.0 in /usr/local/lib/python3.12/dist-packages (from openai) (4.12.1)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /usr/local/lib/python3.12/dist-packages (from openai) (1.9.0)\n",
            "Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.12/dist-packages (from openai) (0.28.1)\n",
            "Requirement already satisfied: jiter<1,>=0.10.0 in /usr/local/lib/python3.12/dist-packages (from openai) (0.12.0)\n",
            "Requirement already satisfied: pydantic<3,>=1.9.0 in /usr/local/lib/python3.12/dist-packages (from openai) (2.12.3)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.12/dist-packages (from openai) (1.3.1)\n",
            "Requirement already satisfied: tqdm>4 in /usr/local/lib/python3.12/dist-packages (from openai) (4.67.1)\n",
            "Requirement already satisfied: typing-extensions<5,>=4.11 in /usr/local/lib/python3.12/dist-packages (from openai) (4.15.0)\n",
            "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.12/dist-packages (from anyio<5,>=3.5.0->openai) (3.11)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.12/dist-packages (from httpx<1,>=0.23.0->openai) (2026.1.4)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.12/dist-packages (from httpx<1,>=0.23.0->openai) (1.0.9)\n",
            "Requirement already satisfied: h11>=0.16 in /usr/local/lib/python3.12/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->openai) (0.16.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.12/dist-packages (from pydantic<3,>=1.9.0->openai) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.41.4 in /usr/local/lib/python3.12/dist-packages (from pydantic<3,>=1.9.0->openai) (2.41.4)\n",
            "Requirement already satisfied: typing-inspection>=0.4.2 in /usr/local/lib/python3.12/dist-packages (from pydantic<3,>=1.9.0->openai) (0.4.2)\n"
          ]
        }
      ],
      "source": [
        "!pip install openai"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install --upgrade openai"
      ],
      "metadata": {
        "id": "qH6qPYGbhthC",
        "outputId": "088de2e4-7548-4ca2-a493-4d218d0c488a",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: openai in /usr/local/lib/python3.12/dist-packages (2.15.0)\n",
            "Requirement already satisfied: anyio<5,>=3.5.0 in /usr/local/lib/python3.12/dist-packages (from openai) (4.12.1)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /usr/local/lib/python3.12/dist-packages (from openai) (1.9.0)\n",
            "Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.12/dist-packages (from openai) (0.28.1)\n",
            "Requirement already satisfied: jiter<1,>=0.10.0 in /usr/local/lib/python3.12/dist-packages (from openai) (0.12.0)\n",
            "Requirement already satisfied: pydantic<3,>=1.9.0 in /usr/local/lib/python3.12/dist-packages (from openai) (2.12.3)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.12/dist-packages (from openai) (1.3.1)\n",
            "Requirement already satisfied: tqdm>4 in /usr/local/lib/python3.12/dist-packages (from openai) (4.67.1)\n",
            "Requirement already satisfied: typing-extensions<5,>=4.11 in /usr/local/lib/python3.12/dist-packages (from openai) (4.15.0)\n",
            "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.12/dist-packages (from anyio<5,>=3.5.0->openai) (3.11)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.12/dist-packages (from httpx<1,>=0.23.0->openai) (2026.1.4)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.12/dist-packages (from httpx<1,>=0.23.0->openai) (1.0.9)\n",
            "Requirement already satisfied: h11>=0.16 in /usr/local/lib/python3.12/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->openai) (0.16.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.12/dist-packages (from pydantic<3,>=1.9.0->openai) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.41.4 in /usr/local/lib/python3.12/dist-packages (from pydantic<3,>=1.9.0->openai) (2.41.4)\n",
            "Requirement already satisfied: typing-inspection>=0.4.2 in /usr/local/lib/python3.12/dist-packages (from pydantic<3,>=1.9.0->openai) (0.4.2)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from openai import OpenAI\n",
        "import os\n",
        "import json\n",
        "from IPython.core.display import display, HTML"
      ],
      "metadata": {
        "id": "-9FVxvOLUBJn"
      },
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import warnings\n",
        "\n",
        "# Filter out all DeprecationWarnings\n",
        "warnings.filterwarnings(\"ignore\", category=DeprecationWarning)"
      ],
      "metadata": {
        "id": "Ik601SYXkjW7"
      },
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def show_json(obj):\n",
        "    display(json.loads(obj.model_dump_json()))"
      ],
      "metadata": {
        "id": "yjYBLPRuXrRN"
      },
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "4r8KGUM2u8fe"
      },
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# We need this to load the files onto google colab\n",
        "!git clone https://github.com/thousandoaks/GenerativeAI4DS-I.git"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JgUvxZ50u8Zx",
        "outputId": "d31c5590-a83f-4659-be3d-47d29f982395"
      },
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "fatal: destination path 'GenerativeAI4DS-I' already exists and is not an empty directory.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 1. You have to get your [OpenAI API Key](https://platform.openai.com/account/api-keys)"
      ],
      "metadata": {
        "id": "ZERbLRu8UEOa"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Used by the agent in this tutorial\n",
        "os.environ[\"OPENAI_API_KEY\"] = \"YOUR_OWN_KEY\""
      ],
      "metadata": {
        "id": "S9mx01r0UBHi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "client = OpenAI(\n",
        "  api_key=os.environ['OPENAI_API_KEY'],  # this is also the default, it can be omitted\n",
        ")"
      ],
      "metadata": {
        "id": "2TlZc7DGXJyG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "client"
      ],
      "metadata": {
        "id": "7fdyruJ_hmOG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 2. Financial Assistant\n",
        "An Assistant represents an entity that can be configured to respond to a user's messages using several parameters like model, instructions, and tools.\n",
        "\n",
        "This time we will create a Financial Assistant able to inspect financial documents and answer back questions regarding them.\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "5cmH04nRXM8f"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 2.1. We create a new assistant with file search enabled"
      ],
      "metadata": {
        "id": "sEm1hzrarL4r"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "assistant = client.beta.assistants.create(\n",
        "  name=\"Financial Analyst Assistant\",\n",
        "  instructions=\"You are an expert financial analyst. Use you knowledge base to answer questions about audited financial statements.\",\n",
        "  model=\"gpt-4o\",\n",
        "  tools=[{\"type\": \"file_search\"}],\n",
        ")"
      ],
      "metadata": {
        "id": "ibD2gBYeqrut"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "663tlq0OqrsG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Aq6SEQHcqrpA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 2.2. We upload financial information\n",
        "To access your files, the file_search tool uses the Vector Store object. Upload your files and create a Vector Store to contain them. Once the Vector Store is created, you should poll its status until all files are out of the in_progress state to ensure that all content has finished processing. The SDK provides helpers to uploading and polling in one shot."
      ],
      "metadata": {
        "id": "seRHPFHtqUb4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Create a vector store caled \"Financial Statements\"\n",
        "vector_store = client.vector_stores.create(name=\"Financial Statements\")\n",
        "\n",
        "# Ready the files for upload to OpenAI\n",
        "file_paths = [\"/content/GenerativeAI4DS-I/datasets/Apple_10K.pdf\",\"/content/GenerativeAI4DS-I/datasets/goog-10-k-2023.pdf\"]\n",
        "file_streams = [open(path, \"rb\") for path in file_paths]\n",
        "\n",
        "# Use the upload and poll SDK helper to upload the files, add them to the vector store,\n",
        "# and poll the status of the file batch for completion.\n",
        "file_batch = client.vector_stores.file_batches.upload_and_poll(\n",
        "  vector_store_id=vector_store.id, files=file_streams\n",
        ")\n",
        "\n",
        "# You can print the status and the file counts of the batch to see the result of this operation.\n",
        "print(file_batch.status)\n",
        "print(file_batch.file_counts)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 356
        },
        "id": "blfO9yxQqR-R",
        "outputId": "f61871dc-cec0-446f-b818-dca80e740837"
      },
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-3317847093.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;31m# Use the upload and poll SDK helper to upload the files, add them to the vector store,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;31m# and poll the status of the file batch for completion.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m file_batch = client.vector_stores.file_batches.upload_and_poll(\n\u001b[0m\u001b[1;32m     11\u001b[0m   \u001b[0mvector_store_id\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mvector_store\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mid\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfiles\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfile_streams\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m )\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/openai/resources/vector_stores/file_batches.py\u001b[0m in \u001b[0;36mupload_and_poll\u001b[0;34m(self, vector_store_id, files, max_concurrency, file_ids, poll_interval_ms, chunking_strategy)\u001b[0m\n\u001b[1;32m    365\u001b[0m             \u001b[0mresults\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfuture\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    366\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 367\u001b[0;31m         batch = self.create_and_poll(\n\u001b[0m\u001b[1;32m    368\u001b[0m             \u001b[0mvector_store_id\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mvector_store_id\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    369\u001b[0m             \u001b[0mfile_ids\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mfile_ids\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mid\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mf\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mresults\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/openai/resources/vector_stores/file_batches.py\u001b[0m in \u001b[0;36mcreate_and_poll\u001b[0;34m(self, vector_store_id, file_ids, poll_interval_ms, chunking_strategy)\u001b[0m\n\u001b[1;32m    206\u001b[0m         )\n\u001b[1;32m    207\u001b[0m         \u001b[0;31m# TODO: don't poll unless necessary??\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 208\u001b[0;31m         return self.poll(\n\u001b[0m\u001b[1;32m    209\u001b[0m             \u001b[0mbatch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mid\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    210\u001b[0m             \u001b[0mvector_store_id\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mvector_store_id\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/openai/resources/vector_stores/file_batches.py\u001b[0m in \u001b[0;36mpoll\u001b[0;34m(self, batch_id, vector_store_id, poll_interval_ms)\u001b[0m\n\u001b[1;32m    318\u001b[0m                         \u001b[0mpoll_interval_ms\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1000\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    319\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 320\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sleep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpoll_interval_ms\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0;36m1000\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    321\u001b[0m                 \u001b[0;32mcontinue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    322\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/openai/_resource.py\u001b[0m in \u001b[0;36m_sleep\u001b[0;34m(self, seconds)\u001b[0m\n\u001b[1;32m     25\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_sleep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mseconds\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mfloat\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 27\u001b[0;31m         \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msleep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mseconds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     28\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 2.3 Update the assistant to to use the new Vector Store\n",
        "To make the files accessible to your assistant, update the assistant’s tool_resources with the new vector_store id."
      ],
      "metadata": {
        "id": "ThymdJQtwaWa"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "assistant = client.beta.assistants.update(\n",
        "  assistant_id=assistant.id,\n",
        "  tool_resources={\"file_search\": {\"vector_store_ids\": [vector_store.id]}},\n",
        ")"
      ],
      "metadata": {
        "id": "g1Afon3LqR7q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "0pY-byneqR5U"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 2.4. Create a thread\n",
        "\n",
        "You can also attach files as Message attachments on your thread. Doing so will create another vector_store associated with the thread, or, if there is already a vector store attached to this thread, attach the new files to the existing thread vector store. When you create a Run on this thread, the file search tool will query both the vector_store from your assistant and the vector_store on the thread.\n",
        "\n",
        "In this example, the user attached a copy of Apple’s latest 10-K filing."
      ],
      "metadata": {
        "id": "_DfqY7kFwuiv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Create a thread and attach the file to the message\n",
        "thread = client.beta.threads.create(\n",
        "  messages=[\n",
        "    {\n",
        "      \"role\": \"user\",\n",
        "      \"content\": \"How many shares of AAPL were outstanding at the end of of October 2023?\",\n",
        "\n",
        "    }\n",
        "  ]\n",
        ")\n",
        "\n"
      ],
      "metadata": {
        "id": "e3Z-FM1SqR2t"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 2.5 Create a Run\n",
        "\n",
        "Now, create a Run and observe that the model uses the File Search tool to provide a response to the user’s question."
      ],
      "metadata": {
        "id": "0LfVC9jsxWg-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Use the create and poll SDK helper to create a run and poll the status of\n",
        "# the run until it's in a terminal state.\n",
        "\n",
        "run = client.beta.threads.runs.create_and_poll(\n",
        "    thread_id=thread.id, assistant_id=assistant.id\n",
        ")\n",
        "\n",
        "messages = list(client.beta.threads.messages.list(thread_id=thread.id, run_id=run.id))\n",
        "\n",
        "message_content = messages[0].content[0].text\n",
        "annotations = message_content.annotations\n",
        "citations = []\n",
        "for index, annotation in enumerate(annotations):\n",
        "    message_content.value = message_content.value.replace(annotation.text, f\"[{index}]\")\n",
        "    if file_citation := getattr(annotation, \"file_citation\", None):\n",
        "        cited_file = client.files.retrieve(file_citation.file_id)\n",
        "        citations.append(f\"[{index}] {cited_file.filename}\")\n",
        "\n",
        "print(message_content.value)\n",
        "print(\"\\n\".join(citations))"
      ],
      "metadata": {
        "id": "jPVcK7YVwuMF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "K1kc4SjNwuG4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 2.6 We add more messages to the same thread as needed"
      ],
      "metadata": {
        "id": "3E-5d5PpyqCs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "message2 = client.beta.threads.messages.create(\n",
        "  thread_id=thread.id,\n",
        "  role=\"user\",\n",
        "  content=\"What was the net profit of Google in 2022 and 2023 ?\"\n",
        ")\n",
        "\n",
        "show_json(message2)"
      ],
      "metadata": {
        "id": "vdc_MiQWwuET"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "run = client.beta.threads.runs.create_and_poll(\n",
        "    thread_id=thread.id, assistant_id=assistant.id\n",
        ")\n",
        "\n",
        "show_json(message2)"
      ],
      "metadata": {
        "id": "JwmmICE4qR0H"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "if run.status == 'completed':\n",
        "\n",
        "  messages = list(client.beta.threads.messages.list(thread_id=thread.id, run_id=run.id))\n",
        "\n",
        "  message_content = messages[0].content[0].text\n",
        "  annotations = message_content.annotations\n",
        "  citations = []\n",
        "  for index, annotation in enumerate(annotations):\n",
        "      message_content.value = message_content.value.replace(annotation.text, f\"[{index}]\")\n",
        "      if file_citation := getattr(annotation, \"file_citation\", None):\n",
        "          cited_file = client.files.retrieve(file_citation.file_id)\n",
        "          citations.append(f\"[{index}] {cited_file.filename}\")\n",
        "\n",
        "  print(message_content.value)\n",
        "  print(\"\\n\".join(citations))\n",
        "\n",
        "else:\n",
        "  print(run.status)"
      ],
      "metadata": {
        "id": "8cjp8Y84qRxg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "WAmiZ6oLqRua"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}