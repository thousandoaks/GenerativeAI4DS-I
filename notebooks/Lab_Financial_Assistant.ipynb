{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOaghQ3745j3MBdOSfygVh5"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# GenerativeAI4DS-I\n",
        "## Lab. Financial Assistant\n",
        "\n",
        "\n",
        "##  What I hope you'll get out of this lab\n",
        "* The feeling that you'll \"know where to start\" when you have to consume OpenAI services.\n",
        "* Follow OpenAI's best practices on how to develop assistants"
      ],
      "metadata": {
        "id": "rigxDZTATdb8"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WBJEYnwHTb11",
        "outputId": "bedeaa86-6330-48d4-8ee3-25924bc78140"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting openai\n",
            "  Downloading openai-1.30.3-py3-none-any.whl (320 kB)\n",
            "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/320.6 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[91m━━━━━━━━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m92.2/320.6 kB\u001b[0m \u001b[31m2.7 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K     \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m \u001b[32m317.4/320.6 kB\u001b[0m \u001b[31m5.9 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m320.6/320.6 kB\u001b[0m \u001b[31m4.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: anyio<5,>=3.5.0 in /usr/local/lib/python3.10/dist-packages (from openai) (3.7.1)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /usr/lib/python3/dist-packages (from openai) (1.7.0)\n",
            "Collecting httpx<1,>=0.23.0 (from openai)\n",
            "  Downloading httpx-0.27.0-py3-none-any.whl (75 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m75.6/75.6 kB\u001b[0m \u001b[31m5.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: pydantic<3,>=1.9.0 in /usr/local/lib/python3.10/dist-packages (from openai) (2.7.1)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.10/dist-packages (from openai) (1.3.1)\n",
            "Requirement already satisfied: tqdm>4 in /usr/local/lib/python3.10/dist-packages (from openai) (4.66.4)\n",
            "Requirement already satisfied: typing-extensions<5,>=4.7 in /usr/local/lib/python3.10/dist-packages (from openai) (4.11.0)\n",
            "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3.5.0->openai) (3.7)\n",
            "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3.5.0->openai) (1.2.1)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.23.0->openai) (2024.2.2)\n",
            "Collecting httpcore==1.* (from httpx<1,>=0.23.0->openai)\n",
            "  Downloading httpcore-1.0.5-py3-none-any.whl (77 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m77.9/77.9 kB\u001b[0m \u001b[31m7.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting h11<0.15,>=0.13 (from httpcore==1.*->httpx<1,>=0.23.0->openai)\n",
            "  Downloading h11-0.14.0-py3-none-any.whl (58 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m58.3/58.3 kB\u001b[0m \u001b[31m5.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: annotated-types>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1.9.0->openai) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.18.2 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1.9.0->openai) (2.18.2)\n",
            "Installing collected packages: h11, httpcore, httpx, openai\n",
            "Successfully installed h11-0.14.0 httpcore-1.0.5 httpx-0.27.0 openai-1.30.3\n"
          ]
        }
      ],
      "source": [
        "!pip install openai"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from openai import OpenAI\n",
        "import os\n",
        "import json\n",
        "from IPython.core.display import display, HTML"
      ],
      "metadata": {
        "id": "-9FVxvOLUBJn"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def show_json(obj):\n",
        "    display(json.loads(obj.model_dump_json()))"
      ],
      "metadata": {
        "id": "yjYBLPRuXrRN"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "4r8KGUM2u8fe"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# We need this to load the files onto google colab\n",
        "!git clone https://github.com/thousandoaks/GenerativeAI4DS-I.git"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JgUvxZ50u8Zx",
        "outputId": "dbf4fede-1254-44ca-de58-67ed90541e12"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'GenerativeAI4DS-I'...\n",
            "remote: Enumerating objects: 56, done.\u001b[K\n",
            "remote: Counting objects: 100% (56/56), done.\u001b[K\n",
            "remote: Compressing objects: 100% (50/50), done.\u001b[K\n",
            "remote: Total 56 (delta 15), reused 0 (delta 0), pack-reused 0\u001b[K\n",
            "Receiving objects: 100% (56/56), 973.60 KiB | 11.87 MiB/s, done.\n",
            "Resolving deltas: 100% (15/15), done.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 1. You have to get your [OpenAI API Key](https://platform.openai.com/account/api-keys)"
      ],
      "metadata": {
        "id": "ZERbLRu8UEOa"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Used by the agent in this tutorial\n",
        "os.environ[\"OPENAI_API_KEY\"] = \"YOU-NEED-YOUR-OWN-KEY\""
      ],
      "metadata": {
        "id": "S9mx01r0UBHi"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "client = OpenAI(\n",
        "  api_key=os.environ['OPENAI_API_KEY'],  # this is also the default, it can be omitted\n",
        ")"
      ],
      "metadata": {
        "id": "2TlZc7DGXJyG"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 2. Financial Assistant\n",
        "An Assistant represents an entity that can be configured to respond to a user's messages using several parameters like model, instructions, and tools.\n",
        "\n",
        "This time we will create a Financial Assistant able to inspect financial documents and answer back questions regarding them.\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "5cmH04nRXM8f"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 2.1. We create a new assistant with file search enabled"
      ],
      "metadata": {
        "id": "sEm1hzrarL4r"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "assistant = client.beta.assistants.create(\n",
        "  name=\"Financial Analyst Assistant\",\n",
        "  instructions=\"You are an expert financial analyst. Use you knowledge base to answer questions about audited financial statements.\",\n",
        "  model=\"gpt-4o\",\n",
        "  tools=[{\"type\": \"file_search\"}],\n",
        ")"
      ],
      "metadata": {
        "id": "ibD2gBYeqrut"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "663tlq0OqrsG"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Aq6SEQHcqrpA"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 2.2. We upload financial information\n",
        "To access your files, the file_search tool uses the Vector Store object. Upload your files and create a Vector Store to contain them. Once the Vector Store is created, you should poll its status until all files are out of the in_progress state to ensure that all content has finished processing. The SDK provides helpers to uploading and polling in one shot."
      ],
      "metadata": {
        "id": "seRHPFHtqUb4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Create a vector store caled \"Financial Statements\"\n",
        "vector_store = client.beta.vector_stores.create(name=\"Financial Statements\")\n",
        "\n",
        "# Ready the files for upload to OpenAI\n",
        "file_paths = [\"/content/GenerativeAI4DS-I/datasets/Apple_10K.pdf\",\"/content/GenerativeAI4DS-I/datasets/goog-10-k-2023.pdf\"]\n",
        "file_streams = [open(path, \"rb\") for path in file_paths]\n",
        "\n",
        "# Use the upload and poll SDK helper to upload the files, add them to the vector store,\n",
        "# and poll the status of the file batch for completion.\n",
        "file_batch = client.beta.vector_stores.file_batches.upload_and_poll(\n",
        "  vector_store_id=vector_store.id, files=file_streams\n",
        ")\n",
        "\n",
        "# You can print the status and the file counts of the batch to see the result of this operation.\n",
        "print(file_batch.status)\n",
        "print(file_batch.file_counts)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "blfO9yxQqR-R",
        "outputId": "4a5e4fbd-fe8a-4822-d907-dac7641c5da3"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "completed\n",
            "FileCounts(cancelled=0, completed=2, failed=0, in_progress=0, total=2)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 2.3 Update the assistant to to use the new Vector Store\n",
        "To make the files accessible to your assistant, update the assistant’s tool_resources with the new vector_store id."
      ],
      "metadata": {
        "id": "ThymdJQtwaWa"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "assistant = client.beta.assistants.update(\n",
        "  assistant_id=assistant.id,\n",
        "  tool_resources={\"file_search\": {\"vector_store_ids\": [vector_store.id]}},\n",
        ")"
      ],
      "metadata": {
        "id": "g1Afon3LqR7q"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "0pY-byneqR5U"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 2.4. Create a thread\n",
        "\n",
        "You can also attach files as Message attachments on your thread. Doing so will create another vector_store associated with the thread, or, if there is already a vector store attached to this thread, attach the new files to the existing thread vector store. When you create a Run on this thread, the file search tool will query both the vector_store from your assistant and the vector_store on the thread.\n",
        "\n",
        "In this example, the user attached a copy of Apple’s latest 10-K filing."
      ],
      "metadata": {
        "id": "_DfqY7kFwuiv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Create a thread and attach the file to the message\n",
        "thread = client.beta.threads.create(\n",
        "  messages=[\n",
        "    {\n",
        "      \"role\": \"user\",\n",
        "      \"content\": \"How many shares of AAPL were outstanding at the end of of October 2023?\",\n",
        "\n",
        "    }\n",
        "  ]\n",
        ")\n",
        "\n"
      ],
      "metadata": {
        "id": "e3Z-FM1SqR2t"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 2.5 Create a Run\n",
        "\n",
        "Now, create a Run and observe that the model uses the File Search tool to provide a response to the user’s question."
      ],
      "metadata": {
        "id": "0LfVC9jsxWg-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Use the create and poll SDK helper to create a run and poll the status of\n",
        "# the run until it's in a terminal state.\n",
        "\n",
        "run = client.beta.threads.runs.create_and_poll(\n",
        "    thread_id=thread.id, assistant_id=assistant.id\n",
        ")\n",
        "\n",
        "messages = list(client.beta.threads.messages.list(thread_id=thread.id, run_id=run.id))\n",
        "\n",
        "message_content = messages[0].content[0].text\n",
        "annotations = message_content.annotations\n",
        "citations = []\n",
        "for index, annotation in enumerate(annotations):\n",
        "    message_content.value = message_content.value.replace(annotation.text, f\"[{index}]\")\n",
        "    if file_citation := getattr(annotation, \"file_citation\", None):\n",
        "        cited_file = client.files.retrieve(file_citation.file_id)\n",
        "        citations.append(f\"[{index}] {cited_file.filename}\")\n",
        "\n",
        "print(message_content.value)\n",
        "print(\"\\n\".join(citations))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jPVcK7YVwuMF",
        "outputId": "2f426a12-1e98-4991-b7b3-b0d34925e532"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "As of September 30, 2023, Apple Inc. had 15,550,061 thousand shares of common stock outstanding[0].\n",
            "[0] Apple_10K.pdf\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "K1kc4SjNwuG4"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 2.6 We add more messages to the same thread as needed"
      ],
      "metadata": {
        "id": "3E-5d5PpyqCs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "message2 = client.beta.threads.messages.create(\n",
        "  thread_id=thread.id,\n",
        "  role=\"user\",\n",
        "  content=\"What was the net profit of Google in 2022 and 2023 ?\"\n",
        ")\n",
        "\n",
        "show_json(message2)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 295
        },
        "id": "vdc_MiQWwuET",
        "outputId": "5370d869-ef0c-4bf3-8198-2f4c99dc5026"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "{'id': 'msg_2kYVkUyA3A0UHmSz81J9rrCk',\n",
              " 'assistant_id': None,\n",
              " 'attachments': [],\n",
              " 'completed_at': None,\n",
              " 'content': [{'text': {'annotations': [],\n",
              "    'value': 'What was the net profit of Google in 2022 and 2023 ?'},\n",
              "   'type': 'text'}],\n",
              " 'created_at': 1716826624,\n",
              " 'incomplete_at': None,\n",
              " 'incomplete_details': None,\n",
              " 'metadata': {},\n",
              " 'object': 'thread.message',\n",
              " 'role': 'user',\n",
              " 'run_id': None,\n",
              " 'status': None,\n",
              " 'thread_id': 'thread_MgYnGyD6KvdMATaCY70g1kEI'}"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "run = client.beta.threads.runs.create_and_poll(\n",
        "    thread_id=thread.id, assistant_id=assistant.id\n",
        ")\n",
        "\n",
        "show_json(message2)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 295
        },
        "id": "JwmmICE4qR0H",
        "outputId": "7c77cf31-5744-4613-ddd1-1c7313258d14"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "{'id': 'msg_2kYVkUyA3A0UHmSz81J9rrCk',\n",
              " 'assistant_id': None,\n",
              " 'attachments': [],\n",
              " 'completed_at': None,\n",
              " 'content': [{'text': {'annotations': [],\n",
              "    'value': 'What was the net profit of Google in 2022 and 2023 ?'},\n",
              "   'type': 'text'}],\n",
              " 'created_at': 1716826624,\n",
              " 'incomplete_at': None,\n",
              " 'incomplete_details': None,\n",
              " 'metadata': {},\n",
              " 'object': 'thread.message',\n",
              " 'role': 'user',\n",
              " 'run_id': None,\n",
              " 'status': None,\n",
              " 'thread_id': 'thread_MgYnGyD6KvdMATaCY70g1kEI'}"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "if run.status == 'completed':\n",
        "\n",
        "  messages = list(client.beta.threads.messages.list(thread_id=thread.id, run_id=run.id))\n",
        "\n",
        "  message_content = messages[0].content[0].text\n",
        "  annotations = message_content.annotations\n",
        "  citations = []\n",
        "  for index, annotation in enumerate(annotations):\n",
        "      message_content.value = message_content.value.replace(annotation.text, f\"[{index}]\")\n",
        "      if file_citation := getattr(annotation, \"file_citation\", None):\n",
        "          cited_file = client.files.retrieve(file_citation.file_id)\n",
        "          citations.append(f\"[{index}] {cited_file.filename}\")\n",
        "\n",
        "  print(message_content.value)\n",
        "  print(\"\\n\".join(citations))\n",
        "\n",
        "else:\n",
        "  print(run.status)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8cjp8Y84qRxg",
        "outputId": "76e96e30-c49f-4d85-c4ef-1a6914104ed8"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The net profit of Google (Alphabet Inc.) for the years 2022 and 2023 were as follows:\n",
            "\n",
            "- In 2022, the net profit was $59.972 billion.\n",
            "- In 2023, the net profit was $73.795 billion[0][1].\n",
            "[0] goog-10-k-2023.pdf\n",
            "[1] goog-10-k-2023.pdf\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "WAmiZ6oLqRua"
      },
      "execution_count": 14,
      "outputs": []
    }
  ]
}