{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPpnLAkx5t0CpkcGseJhx3l"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# GenerativeAI4DS-I\n",
        "## Lab. Medical Assistant\n",
        "\n",
        "\n",
        "##  What I hope you'll get out of this lab\n",
        "* The feeling that you'll \"know where to start\" when you have to consume OpenAI services.\n",
        "* Follow OpenAI's best practices on how to develop assistants"
      ],
      "metadata": {
        "id": "rigxDZTATdb8"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WBJEYnwHTb11",
        "outputId": "41368b5f-655c-4402-eb04-1a1c22ce41d1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting openai\n",
            "  Downloading openai-1.30.3-py3-none-any.whl (320 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m320.6/320.6 kB\u001b[0m \u001b[31m2.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: anyio<5,>=3.5.0 in /usr/local/lib/python3.10/dist-packages (from openai) (3.7.1)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /usr/lib/python3/dist-packages (from openai) (1.7.0)\n",
            "Collecting httpx<1,>=0.23.0 (from openai)\n",
            "  Downloading httpx-0.27.0-py3-none-any.whl (75 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m75.6/75.6 kB\u001b[0m \u001b[31m5.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: pydantic<3,>=1.9.0 in /usr/local/lib/python3.10/dist-packages (from openai) (2.7.1)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.10/dist-packages (from openai) (1.3.1)\n",
            "Requirement already satisfied: tqdm>4 in /usr/local/lib/python3.10/dist-packages (from openai) (4.66.4)\n",
            "Requirement already satisfied: typing-extensions<5,>=4.7 in /usr/local/lib/python3.10/dist-packages (from openai) (4.11.0)\n",
            "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3.5.0->openai) (3.7)\n",
            "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3.5.0->openai) (1.2.1)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.23.0->openai) (2024.2.2)\n",
            "Collecting httpcore==1.* (from httpx<1,>=0.23.0->openai)\n",
            "  Downloading httpcore-1.0.5-py3-none-any.whl (77 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m77.9/77.9 kB\u001b[0m \u001b[31m6.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting h11<0.15,>=0.13 (from httpcore==1.*->httpx<1,>=0.23.0->openai)\n",
            "  Downloading h11-0.14.0-py3-none-any.whl (58 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m58.3/58.3 kB\u001b[0m \u001b[31m5.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: annotated-types>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1.9.0->openai) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.18.2 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1.9.0->openai) (2.18.2)\n",
            "Installing collected packages: h11, httpcore, httpx, openai\n",
            "Successfully installed h11-0.14.0 httpcore-1.0.5 httpx-0.27.0 openai-1.30.3\n"
          ]
        }
      ],
      "source": [
        "!pip install openai"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from openai import OpenAI\n",
        "import os\n",
        "import json\n",
        "from IPython.core.display import display, HTML"
      ],
      "metadata": {
        "id": "-9FVxvOLUBJn"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def show_json(obj):\n",
        "    display(json.loads(obj.model_dump_json()))"
      ],
      "metadata": {
        "id": "yjYBLPRuXrRN"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "4r8KGUM2u8fe"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# We need this to load the files onto google colab\n",
        "!git clone https://github.com/thousandoaks/GenerativeAI4DS-I.git"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JgUvxZ50u8Zx",
        "outputId": "5fd9abf4-2150-4583-dbdb-ab2088495c5a"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'GenerativeAI4DS-I'...\n",
            "remote: Enumerating objects: 73, done.\u001b[K\n",
            "remote: Counting objects: 100% (73/73), done.\u001b[K\n",
            "remote: Compressing objects: 100% (67/67), done.\u001b[K\n",
            "remote: Total 73 (delta 23), reused 0 (delta 0), pack-reused 0\u001b[K\n",
            "Receiving objects: 100% (73/73), 982.13 KiB | 5.74 MiB/s, done.\n",
            "Resolving deltas: 100% (23/23), done.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 1. You have to get your [OpenAI API Key](https://platform.openai.com/account/api-keys)"
      ],
      "metadata": {
        "id": "ZERbLRu8UEOa"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Used by the agent in this tutorial\n",
        "os.environ[\"OPENAI_API_KEY\"] = \"YOU-NEED-YOUR-OWN-KEY\""
      ],
      "metadata": {
        "id": "S9mx01r0UBHi"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "client = OpenAI(\n",
        "  api_key=os.environ['OPENAI_API_KEY'],  # this is also the default, it can be omitted\n",
        ")"
      ],
      "metadata": {
        "id": "2TlZc7DGXJyG"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 2. Medical Assistant\n",
        "An Assistant represents an entity that can be configured to respond to a user's messages using several parameters like model, instructions, and tools.\n",
        "\n",
        "This time we will create a Medical Assistant able to inspect healthcare records and summarize medical events\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "5cmH04nRXM8f"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 2.1. We create a new assistant with file search enabled"
      ],
      "metadata": {
        "id": "sEm1hzrarL4r"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "assistant = client.beta.assistants.create(\n",
        "  name=\"Medical Analyst Assistant\",\n",
        "  instructions=\"You are a data scientist with experience in healthcare. Use you knowledge base to answer questions about medical reports.\",\n",
        "  model=\"gpt-4o\",\n",
        "  tools=[{\"type\": \"file_search\"}],\n",
        ")"
      ],
      "metadata": {
        "id": "ibD2gBYeqrut"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "663tlq0OqrsG"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Aq6SEQHcqrpA"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 2.2. We upload financial information\n",
        "To access your files, the file_search tool uses the Vector Store object. Upload your files and create a Vector Store to contain them. Once the Vector Store is created, you should poll its status until all files are out of the in_progress state to ensure that all content has finished processing. The SDK provides helpers to uploading and polling in one shot."
      ],
      "metadata": {
        "id": "seRHPFHtqUb4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Create a vector store caled \"Financial Statements\"\n",
        "vector_store = client.beta.vector_stores.create(name=\"Financial Statements\")\n",
        "\n",
        "# Ready the files for upload to OpenAI\n",
        "file_paths = [\"/content/GenerativeAI4DS-I/datasets/06b03cbb.txt\",\"/content/GenerativeAI4DS-I/datasets/08f08ba5.txt\"]\n",
        "file_streams = [open(path, \"rb\") for path in file_paths]\n",
        "\n",
        "# Use the upload and poll SDK helper to upload the files, add them to the vector store,\n",
        "# and poll the status of the file batch for completion.\n",
        "file_batch = client.beta.vector_stores.file_batches.upload_and_poll(\n",
        "  vector_store_id=vector_store.id, files=file_streams\n",
        ")\n",
        "\n",
        "# You can print the status and the file counts of the batch to see the result of this operation.\n",
        "print(file_batch.status)\n",
        "print(file_batch.file_counts)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "blfO9yxQqR-R",
        "outputId": "8ec61720-f4ec-4170-de51-1f54526b241a"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "failed\n",
            "FileCounts(cancelled=0, completed=0, failed=2, in_progress=0, total=2)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 2.3 Update the assistant to to use the new Vector Store\n",
        "To make the files accessible to your assistant, update the assistant’s tool_resources with the new vector_store id."
      ],
      "metadata": {
        "id": "ThymdJQtwaWa"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "assistant = client.beta.assistants.update(\n",
        "  assistant_id=assistant.id,\n",
        "  tool_resources={\"file_search\": {\"vector_store_ids\": [vector_store.id]}},\n",
        ")"
      ],
      "metadata": {
        "id": "g1Afon3LqR7q"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "0pY-byneqR5U"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 2.4. Create a thread\n",
        "\n",
        "You can also attach files as Message attachments on your thread. Doing so will create another vector_store associated with the thread, or, if there is already a vector store attached to this thread, attach the new files to the existing thread vector store. When you create a Run on this thread, the file search tool will query both the vector_store from your assistant and the vector_store on the thread.\n",
        "\n"
      ],
      "metadata": {
        "id": "_DfqY7kFwuiv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Create a thread and attach the file to the message\n",
        "thread = client.beta.threads.create(\n",
        "  messages=[\n",
        "    {\n",
        "      \"role\": \"user\",\n",
        "      \"content\": \"Summarize the medical event experienced by subscriber ID: 06b03cbb\",\n",
        "\n",
        "    }\n",
        "  ]\n",
        ")\n",
        "\n"
      ],
      "metadata": {
        "id": "e3Z-FM1SqR2t"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 2.5 Create a Run\n",
        "\n",
        "Now, create a Run and observe that the model uses the File Search tool to provide a response to the user’s question."
      ],
      "metadata": {
        "id": "0LfVC9jsxWg-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Use the create and poll SDK helper to create a run and poll the status of\n",
        "# the run until it's in a terminal state.\n",
        "\n",
        "run = client.beta.threads.runs.create_and_poll(\n",
        "    thread_id=thread.id, assistant_id=assistant.id\n",
        ")\n",
        "\n",
        "messages = list(client.beta.threads.messages.list(thread_id=thread.id, run_id=run.id))\n",
        "\n",
        "message_content = messages[0].content[0].text\n",
        "annotations = message_content.annotations\n",
        "citations = []\n",
        "for index, annotation in enumerate(annotations):\n",
        "    message_content.value = message_content.value.replace(annotation.text, f\"[{index}]\")\n",
        "    if file_citation := getattr(annotation, \"file_citation\", None):\n",
        "        cited_file = client.files.retrieve(file_citation.file_id)\n",
        "        citations.append(f\"[{index}] {cited_file.filename}\")\n",
        "\n",
        "print(message_content.value)\n",
        "print(\"\\n\".join(citations))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jPVcK7YVwuMF",
        "outputId": "34335f9a-1ad9-465d-a795-778b1c6b8967"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Subscriber ID: 06b03cbb experienced a significant medical event detailed in the records. On December 2, 2020, the subscriber had an X-ray imaging procedure due to concerns of pulmonary consolidation. The findings suggested the presence of multi-lobar pneumonia, and the overall impression was consistent with this diagnosis. The subscriber's medical record indicates that they were experiencing symptoms significant enough to warrant imaging diagnostics and medical intervention .\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "K1kc4SjNwuG4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "cANTXxScM_6E"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "BRo65ZzzM_1Z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 2.6 We add more messages to the same thread as needed"
      ],
      "metadata": {
        "id": "3E-5d5PpyqCs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "message2 = client.beta.threads.messages.create(\n",
        "  thread_id=thread.id,\n",
        "  role=\"user\",\n",
        "  content=\"Was it a serious medical event ?\"\n",
        ")\n",
        "\n",
        "show_json(message2)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 295
        },
        "id": "vdc_MiQWwuET",
        "outputId": "2a549b35-2f10-4028-8029-9e7326340ca9"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "{'id': 'msg_ldRRVNRvook8cHk26pz6aYIr',\n",
              " 'assistant_id': None,\n",
              " 'attachments': [],\n",
              " 'completed_at': None,\n",
              " 'content': [{'text': {'annotations': [],\n",
              "    'value': 'Was it a serious medical event ?'},\n",
              "   'type': 'text'}],\n",
              " 'created_at': 1716883054,\n",
              " 'incomplete_at': None,\n",
              " 'incomplete_details': None,\n",
              " 'metadata': {},\n",
              " 'object': 'thread.message',\n",
              " 'role': 'user',\n",
              " 'run_id': None,\n",
              " 'status': None,\n",
              " 'thread_id': 'thread_5WM345ZMGmN2ET3Ag75bT4s3'}"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "run = client.beta.threads.runs.create_and_poll(\n",
        "    thread_id=thread.id, assistant_id=assistant.id\n",
        ")\n",
        "\n",
        "show_json(message2)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 295
        },
        "id": "JwmmICE4qR0H",
        "outputId": "5dba9423-1296-45b2-af6b-8c1e41ea03d4"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "{'id': 'msg_ldRRVNRvook8cHk26pz6aYIr',\n",
              " 'assistant_id': None,\n",
              " 'attachments': [],\n",
              " 'completed_at': None,\n",
              " 'content': [{'text': {'annotations': [],\n",
              "    'value': 'Was it a serious medical event ?'},\n",
              "   'type': 'text'}],\n",
              " 'created_at': 1716883054,\n",
              " 'incomplete_at': None,\n",
              " 'incomplete_details': None,\n",
              " 'metadata': {},\n",
              " 'object': 'thread.message',\n",
              " 'role': 'user',\n",
              " 'run_id': None,\n",
              " 'status': None,\n",
              " 'thread_id': 'thread_5WM345ZMGmN2ET3Ag75bT4s3'}"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "if run.status == 'completed':\n",
        "\n",
        "  messages = list(client.beta.threads.messages.list(thread_id=thread.id, run_id=run.id))\n",
        "\n",
        "  message_content = messages[0].content[0].text\n",
        "  annotations = message_content.annotations\n",
        "  citations = []\n",
        "  for index, annotation in enumerate(annotations):\n",
        "      message_content.value = message_content.value.replace(annotation.text, f\"[{index}]\")\n",
        "      if file_citation := getattr(annotation, \"file_citation\", None):\n",
        "          cited_file = client.files.retrieve(file_citation.file_id)\n",
        "          citations.append(f\"[{index}] {cited_file.filename}\")\n",
        "\n",
        "  print(message_content.value)\n",
        "  print(\"\\n\".join(citations))\n",
        "\n",
        "else:\n",
        "  print(run.status)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8cjp8Y84qRxg",
        "outputId": "d12c4de6-5964-4080-85f7-660a6a880365"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Yes, the medical event experienced by subscriber ID: 06b03cbb was serious. Multi-lobar pneumonia is considered a severe condition as it affects multiple lobes of the lungs, which can lead to significant respiratory distress and requires timely medical intervention to manage effectively.\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 2.7 We add more messages to the same thread as needed"
      ],
      "metadata": {
        "id": "_hyCTTxuNt3m"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "message3 = client.beta.threads.messages.create(\n",
        "  thread_id=thread.id,\n",
        "  role=\"user\",\n",
        "  content=\"What happened to subscriber ID 08f08ba5?\"\n",
        ")\n",
        "\n",
        "show_json(message3)"
      ],
      "metadata": {
        "id": "WAmiZ6oLqRua",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 295
        },
        "outputId": "4124414d-49ec-416b-af46-3dd2c4c0541d"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "{'id': 'msg_OGUQ7SBdWaYREjdx3kDzK6vg',\n",
              " 'assistant_id': None,\n",
              " 'attachments': [],\n",
              " 'completed_at': None,\n",
              " 'content': [{'text': {'annotations': [],\n",
              "    'value': 'What happened to subscriber ID 08f08ba5?'},\n",
              "   'type': 'text'}],\n",
              " 'created_at': 1716883306,\n",
              " 'incomplete_at': None,\n",
              " 'incomplete_details': None,\n",
              " 'metadata': {},\n",
              " 'object': 'thread.message',\n",
              " 'role': 'user',\n",
              " 'run_id': None,\n",
              " 'status': None,\n",
              " 'thread_id': 'thread_5WM345ZMGmN2ET3Ag75bT4s3'}"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "run = client.beta.threads.runs.create_and_poll(\n",
        "    thread_id=thread.id, assistant_id=assistant.id\n",
        ")\n",
        "\n",
        "show_json(message3)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 295
        },
        "id": "-CrEtz_8N62S",
        "outputId": "0e968f2a-c8b0-4c01-ccec-9e378481acf0"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "{'id': 'msg_OGUQ7SBdWaYREjdx3kDzK6vg',\n",
              " 'assistant_id': None,\n",
              " 'attachments': [],\n",
              " 'completed_at': None,\n",
              " 'content': [{'text': {'annotations': [],\n",
              "    'value': 'What happened to subscriber ID 08f08ba5?'},\n",
              "   'type': 'text'}],\n",
              " 'created_at': 1716883306,\n",
              " 'incomplete_at': None,\n",
              " 'incomplete_details': None,\n",
              " 'metadata': {},\n",
              " 'object': 'thread.message',\n",
              " 'role': 'user',\n",
              " 'run_id': None,\n",
              " 'status': None,\n",
              " 'thread_id': 'thread_5WM345ZMGmN2ET3Ag75bT4s3'}"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "if run.status == 'completed':\n",
        "\n",
        "  messages = list(client.beta.threads.messages.list(thread_id=thread.id, run_id=run.id))\n",
        "\n",
        "  message_content = messages[0].content[0].text\n",
        "  annotations = message_content.annotations\n",
        "  citations = []\n",
        "  for index, annotation in enumerate(annotations):\n",
        "      message_content.value = message_content.value.replace(annotation.text, f\"[{index}]\")\n",
        "      if file_citation := getattr(annotation, \"file_citation\", None):\n",
        "          cited_file = client.files.retrieve(file_citation.file_id)\n",
        "          citations.append(f\"[{index}] {cited_file.filename}\")\n",
        "\n",
        "  print(message_content.value)\n",
        "  print(\"\\n\".join(citations))\n",
        "\n",
        "else:\n",
        "  print(run.status)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0uNnayK6N-Bo",
        "outputId": "1fd2279c-d6fd-4b17-84bd-49d0f6466c19"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Subscriber ID: 08f08ba5 underwent an ultrasound procedure on December 9, 2020, specifically to examine the kidneys, ureter, and bladder . This suggests that there might have been a concern related to these areas, prompting the need for imaging to aid in diagnosis or management.\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "message4 = client.beta.threads.messages.create(\n",
        "  thread_id=thread.id,\n",
        "  role=\"user\",\n",
        "  content=\"Any other medical procedure you would have advised conducting for subscriber 08f08ba5?\"\n",
        ")\n",
        "\n",
        "show_json(message4)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 295
        },
        "id": "AoLGHel_OQEF",
        "outputId": "9c1b812f-951f-4e6a-ffcc-487ddc3a8332"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "{'id': 'msg_11nb2fJfcJqgwjVdXf7uDxft',\n",
              " 'assistant_id': None,\n",
              " 'attachments': [],\n",
              " 'completed_at': None,\n",
              " 'content': [{'text': {'annotations': [],\n",
              "    'value': 'Any other medical procedure you would have advised conducting for subscriber 08f08ba5?'},\n",
              "   'type': 'text'}],\n",
              " 'created_at': 1716883406,\n",
              " 'incomplete_at': None,\n",
              " 'incomplete_details': None,\n",
              " 'metadata': {},\n",
              " 'object': 'thread.message',\n",
              " 'role': 'user',\n",
              " 'run_id': None,\n",
              " 'status': None,\n",
              " 'thread_id': 'thread_5WM345ZMGmN2ET3Ag75bT4s3'}"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "run = client.beta.threads.runs.create_and_poll(\n",
        "    thread_id=thread.id, assistant_id=assistant.id\n",
        ")\n",
        "\n",
        "show_json(message4)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 295
        },
        "id": "3KmvBvPpObwD",
        "outputId": "79cab1db-556b-48ab-d917-aa0f1beb3a93"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "{'id': 'msg_11nb2fJfcJqgwjVdXf7uDxft',\n",
              " 'assistant_id': None,\n",
              " 'attachments': [],\n",
              " 'completed_at': None,\n",
              " 'content': [{'text': {'annotations': [],\n",
              "    'value': 'Any other medical procedure you would have advised conducting for subscriber 08f08ba5?'},\n",
              "   'type': 'text'}],\n",
              " 'created_at': 1716883406,\n",
              " 'incomplete_at': None,\n",
              " 'incomplete_details': None,\n",
              " 'metadata': {},\n",
              " 'object': 'thread.message',\n",
              " 'role': 'user',\n",
              " 'run_id': None,\n",
              " 'status': None,\n",
              " 'thread_id': 'thread_5WM345ZMGmN2ET3Ag75bT4s3'}"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "if run.status == 'completed':\n",
        "\n",
        "  messages = list(client.beta.threads.messages.list(thread_id=thread.id, run_id=run.id))\n",
        "\n",
        "  message_content = messages[0].content[0].text\n",
        "  annotations = message_content.annotations\n",
        "  citations = []\n",
        "  for index, annotation in enumerate(annotations):\n",
        "      message_content.value = message_content.value.replace(annotation.text, f\"[{index}]\")\n",
        "      if file_citation := getattr(annotation, \"file_citation\", None):\n",
        "          cited_file = client.files.retrieve(file_citation.file_id)\n",
        "          citations.append(f\"[{index}] {cited_file.filename}\")\n",
        "\n",
        "  print(message_content.value)\n",
        "  print(\"\\n\".join(citations))\n",
        "\n",
        "else:\n",
        "  print(run.status)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aoa1-fByOeXt",
        "outputId": "522f3fac-5e4c-46f9-ab5b-715a7eed32b3"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Based on the information provided, subscriber ID: 08f08ba5 had an ultrasound procedure to examine the kidneys, ureter, and bladder. Depending on the results of the ultrasound and the clinical presentation of the patient, the following additional procedures might be advised:\n",
            "\n",
            "1. **Urinalysis**: To check for infection, presence of blood, protein, and other abnormalities.\n",
            "2. **Blood tests**: To evaluate kidney function (including serum creatinine and blood urea nitrogen levels) and overall metabolic function.\n",
            "3. **CT scan or MRI**: If more detailed imaging is necessary to evaluate the structure and any abnormalities more precisely than what an ultrasound can provide.\n",
            "4. **Cystoscopy**: For a direct visual inspection of the bladder and urethra if there are symptoms such as blood in the urine.\n",
            "5. **Biopsy**: If there are any suspicious masses or lesions detected during the imaging that warrant further examination.\n",
            "6. **Renal function tests**: To assess how well the kidneys are filtering waste (e.g., glomerular filtration rate [GFR]).\n",
            "\n",
            "The decision for additional procedures should be based on the findings from the initial ultrasound and the patient's symptoms and medical history.\n",
            "\n"
          ]
        }
      ]
    }
  ]
}